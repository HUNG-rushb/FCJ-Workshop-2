[
{
	"uri": "//localhost:1313/",
	"title": "AWS S3 Logging",
	"tags": [],
	"description": "",
	"content": "AWS S3 Logging Workshop Overall In this workshop, we will use AWS S3 server access logging and AWS CloudTrail to logging when thereis operation on our S3 objects. Then we will use AWS Athena to query log.\nContent Introduction Preparation S3 Server Access Logging Apply AWS CloudTrail Log query with Athena Clean up "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.1-2buckets/",
	"title": "Create 2 bucket ",
	"tags": [],
	"description": "",
	"content": "Create 2 bucket At AWS Management Console, find S3 and select S3. At S3 console, select Create bucket. In create bucket steps: For AWS Region, select Asia Pacific (Singapore) ap-southeast-1. For Bucket name, insert logging-workshop. Tiếp tục: For Block Public Access settings for this bucket, untick Block all public access. For Turning off block all public access might result in this bucket and the objects within becoming public, confirm this. Scroll down, select Create bucket. Confirm bucket is created successfully. Continue creating bucket logging-workshop-destination For AWS Region, select Asia Pacific (Singapore) ap-southeast-1. For Bucket name, insert logging-workshop-destination. No need to untick Block Public Access settings for this bucket. Scroll down, select Create bucket. Confirm bucket is created successfully. "
},
{
	"uri": "//localhost:1313/3-s3sal/3.1-sal/",
	"title": "Enable S3 Server access logging",
	"tags": [],
	"description": "",
	"content": "In this step, we will enable Server access logging.\nServer access logs give you visibility into detailed object-level operations on your data. The log files are text files that have one line for each log record. Each log record represents one request and consists of space-delimited fields.\nThe fields relate to operation, requester, resource, and session information. Here is an example:\n79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be awsexamplebucket1 [06/Feb/2019:00:00:38 +0000] 192.0.2.3 79a59df900b949e55d96a1e698fbacedfd6e09d98eacf8f8d5218e7cd47ef2be 3E57427F3EXAMPLE REST.GET.VERSIONING - \u0026#34;GET /awsexamplebucket1?versioning HTTP/1.1\u0026#34; 200 - 113 - 7 - \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4\u0026#34; - s9lzHYrFp76ZVxRcpX9+5cjAnEH2ROuNkd2BHfIa6UkFVdtjf5mKR3/eTPFvsiP/XV/VLi31234= SigV2 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader awsexamplebucket1.s3.us-west-1.amazonaws.com TLSV1.1 Kích hoạt Server access logging In S3 console, select bucket logging-workshop. In bucket console, select Properties. Scroll dowm to Server access logging, select Edit Select Enable, then select Brow S3 for storing the logs afterward. Select bucket logging-workshop-destination, then select Choose destination. Review bucket, then select Save changes. Confirm Server access logging is enabled. "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "When you use logging with Amazon S3, you can record actions taken by users, and services on your Amazon S3 resources. You can then use the log records for auditing and compliance purposes.\nYou can log Amazon S3 actions using server access logs or AWS CloudTrail logs.\nServer access logging is a mechanism that provides detailed records for requests made to an S3 bucket.\nServer access logging is disabled by default. Enable server access logging to start receiving logs. Log records are generally delivered within a few hours and it is rare to lose log records. There is no charge for enabling access logging, nor for PUT operations for log files. You are only charged for storage of the logs and for GET operations on the files. You can use object lifecycle management to minimize storage costs.\nAWS CloudTrail is a service that provides records of actions taken by a user, role, or service in your AWS Account. You can use CloudTrail to audit your account by logging and monitoring all activity. You can also use CloudTrail to detect unusual activity in your account.\nLogging Amazon S3 actions with AWS CloudTrail helps keep your account secure by providing access auditing and analysis.\nComparison\nLog properties AWS CloudTrail Amazon S3 server logs Can be forwarded to other systems (Amazon CloudWatch Logs, Amazon CloudWatch Events) Yes No Deliver logs to more than one destination (for example, send the same logs to two different buckets) Yes No Turn on logs for a subset of objects (prefix) Yes No Cross-account log delivery (target and source bucket owned by different accounts) Yes No Integrity validation of log file by using digital signature or hashing Yes No Default or choice of encryption for log files Yes No Object operations (by using Amazon S3 APIs) Yes Yes Bucket operations (by using Amazon S3 APIs) Yes Yes Searchable UI for logs Yes No Fields for Object Lock parameters, Amazon S3 Select properties for log records Yes No Amazon Athena is an interactive query service that makes it easy for you to analyze data in Amazon S3 using standard SQL. You do not need to manage any infrastructure with Athena, and you pay only for the queries that you run.\nOnce you enable server access logs and store them in your target S3 bucket, you might want to analyze or search through them. Logs are not automatically analyzed by Amazon S3, and you might have a lot of data. To analyze all your Amazon S3 data, you can use Amazon Athena.\n"
},
{
	"uri": "//localhost:1313/3-s3sal/3.2-log/",
	"title": "Check logs",
	"tags": [],
	"description": "",
	"content": "Truy cập file và kiễm tra log Open new private tab and acces the file.\nIn buckets console, select bucket logging-workshop-destination, wait about 15 minutes, refresh the bucket.\nWe can see there are logs there, select one. Select Download and open it. the log file will looks like below: b07c1e6c73fc3be646182d0400a50638e0703b6352275b2d165aa35f9791c572 logging-workshop [03/Mar/2024:12:52:26 +0000] 118.69.159.186 arn:aws:iam::928738046450:user/hung 2ET0N53Y32R632Q5 REST.GET.OWNERSHIP_CONTROLS - \u0026#34;GET /logging-workshop?ownershipControls= HTTP/1.1\u0026#34; 200 - 193 - 53 53 \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4, aws-internal/3 aws-sdk-java/1.12.488 Linux/5.10.209-175.858.amzn2int.x86_64 OpenJDK_64-Bit_Server_VM/25.372-b08 java/1.8.0_372 vendor/Oracle_Corporation cfg/retry-mode/standard\u0026#34; - xqa7XzBU4q1xnx4NmkVBFhDsnt0jk07Slo9F3j2kvD0/6zSveFBzQ5t+Zrfs/me6L4epr6/dG3k= SigV4 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader s3.ap-southeast-1.amazonaws.com TLSv1.2 - -\rb07c1e6c73fc3be646182d0400a50638e0703b6352275b2d165aa35f9791c572 logging-workshop [03/Mar/2024:12:52:28 +0000] 118.69.159.186 arn:aws:iam::928738046450:user/hung YP9K97RHY7C5JPBC REST.GET.OBJECT_TAGGING S3_logging_workshop.txt \u0026#34;GET /logging-workshop/S3_logging_workshop.txt?tagging= HTTP/1.1\u0026#34; 200 - 115 - 13 10 \u0026#34;-\u0026#34; \u0026#34;S3Console/0.4, aws-internal/3 aws-sdk-java/1.12.488 Linux/5.10.209-175.858.amzn2int.x86_64 OpenJDK_64-Bit_Server_VM/25.372-b08 java/1.8.0_372 vendor/Oracle_Corporation cfg/retry-mode/standard\u0026#34; - nGxxv80fXE5xGWiS6C7OIg7/ncxoVho61Lmw9+qyveqdOBbiqRD4HJZf8qU90j0IeUXNGmwcSwA= SigV4 ECDHE-RSA-AES128-GCM-SHA256 AuthHeader s3.ap-southeast-1.amazonaws.com TLSv1.2 - - "
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Preparation ",
	"tags": [],
	"description": "",
	"content": "To prepare for this workshop, we will create 1 group with public access to hold the files we need to access and 1 private group to hold the server access logs.\nContent Create 2 bucket Update permissiong Upload file to bucket Add policy for bucket Access files "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-permission/",
	"title": "Update logging permission ",
	"tags": [],
	"description": "",
	"content": "Cập nhật quyền tạo log cho S3 log delivery group Return to bucket console, select bucket logging-workshop-destination. Scroll down to section Object Ownership, select Edit Select ACLs enabled, confirm I acknowledge that ACLS will be restored., select Save changes. This will make everythin in the Access control list (ACL) can create object. Scroll down to section Access control list (ACL), select Edit. At S3 log delivery group, select Write, then Save changes. Confrim Write for S3 log delivery group. Return to bucket console. "
},
{
	"uri": "//localhost:1313/3-s3sal/",
	"title": "S3 Server Access Logging",
	"tags": [],
	"description": "",
	"content": "In this step, we will enable Server access logging.\nContent Enable S3 Server Access Logging Check log "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.3-upload/",
	"title": "Upload file to S3 bucket ",
	"tags": [],
	"description": "",
	"content": "Upload file vào bucket Select bucket logging-workshop. Then, select Upload. Select Add files. Then: Download S3_logging_workshop.txt here Attachments\rS3_logging_workshop.txt\r(0 ko)\rOpen in a new tab, Ctrl + S to save the file to your local.\nconfirm the file is selected Select Upload. Confirm uploaded successfully. "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.4-policy/",
	"title": "Edit policy ",
	"tags": [],
	"description": "",
	"content": "Thêm policy cho bucket In S3 console, select logging-workshop bucket. Select Permissions tab. for Bucket policy, select Edit. Insert: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::logging-workshop/*\u0026#34; } ] } Chọn Save changes Confirm updated successfully "
},
{
	"uri": "//localhost:1313/4-s3cloudtrail/",
	"title": "Logging with AWS CloudTrail",
	"tags": [],
	"description": "",
	"content": " CloudTrail includes 3 main components: Event A record of an activity in an AWS account.. Trail A trail enables CloudTrail to deliver log files to an Amazon S3 bucket, CloudWatch logs, and CloudWatch events. Log bucket The target S3 bucket where logs files are delivered. Kích hoạt Server access logging In AWS Console, find and choose Cloudtrail. Select Create trail Continue: For Trail name, insert S3_logging_workshop. For Trail log bucket and folder, insert aws-cloud-trail-logs-workshop. For Log file SSE-KMS encryption, untick Enable. Scroll down and select Next. For Event type, tick Data events. Scroll down, for Data events, select S3. Then hit Next. Review and select Create trail. Confirm trail is created. Return S3 console, we can see that aws-cloud-trail-logs-workshop is created for storing logs. Open private tab and access the file.\nWait 10 minuts then refresh. Follow, get into inners folder until you can see the logs.\nSelect a file and Download. Log file will look like this: { \u0026#34;Records\u0026#34;: [ { \u0026#34;eventVersion\u0026#34;: \u0026#34;1.09\u0026#34;, \u0026#34;userIdentity\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;IAMUser\u0026#34;, \u0026#34;principalId\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:iam::****:user/****\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;accessKeyId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;****\u0026#34;, \u0026#34;sessionContext\u0026#34;: { \u0026#34;attributes\u0026#34;: { \u0026#34;creationDate\u0026#34;: \u0026#34;2024-03-03T05:32:58Z\u0026#34;, \u0026#34;mfaAuthenticated\u0026#34;: \u0026#34;false\u0026#34; } } }, \u0026#34;eventTime\u0026#34;: \u0026#34;2024-03-03T14:00:32Z\u0026#34;, \u0026#34;eventSource\u0026#34;: \u0026#34;s3.amazonaws.com\u0026#34;, \u0026#34;eventName\u0026#34;: \u0026#34;GetObject\u0026#34;, \u0026#34;awsRegion\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;sourceIPAddress\u0026#34;: \u0026#34;118.69.159.186\u0026#34;, \u0026#34;userAgent\u0026#34;: \u0026#34;[Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0]\u0026#34;, \u0026#34;requestParameters\u0026#34;: { \u0026#34;X-Amz-Date\u0026#34;: \u0026#34;20240303T140026Z\u0026#34;, \u0026#34;bucketName\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop\u0026#34;, \u0026#34;X-Amz-Algorithm\u0026#34;: \u0026#34;AWS4-HMAC-SHA256\u0026#34;, \u0026#34;response-content-disposition\u0026#34;: \u0026#34;attachment\u0026#34;, \u0026#34;X-Amz-SignedHeaders\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop.s3.ap-southeast-1.amazonaws.com\u0026#34;, \u0026#34;X-Amz-Expires\u0026#34;: \u0026#34;300\u0026#34;, \u0026#34;key\u0026#34;: \u0026#34;AWSLogs/*****/CloudTrail/ap-southeast-1/2024/03/03/*****_CloudTrail_ap-southeast-1_20240303T1355Z_FXZWnsQMI7Esmlr6.json.gz\u0026#34; }, \u0026#34;responseElements\u0026#34;: null, \u0026#34;additionalEventData\u0026#34;: { \u0026#34;SignatureVersion\u0026#34;: \u0026#34;SigV4\u0026#34;, \u0026#34;CipherSuite\u0026#34;: \u0026#34;ECDHE-RSA-AES128-GCM-SHA256\u0026#34;, \u0026#34;bytesTransferredIn\u0026#34;: 0, \u0026#34;AuthenticationMethod\u0026#34;: \u0026#34;QueryString\u0026#34;, \u0026#34;x-amz-id-2\u0026#34;: \u0026#34;0nSxx7oCCBTlrpXwQsLYoA0MqHo/+k/FiMnikrVCDKiWDr1Aoeg7oSqlJvBsYm2J3BnFpU31IUA=\u0026#34;, \u0026#34;bytesTransferredOut\u0026#34;: 7759 }, \u0026#34;requestID\u0026#34;: \u0026#34;MB8NVKR3FVMSSRM9\u0026#34;, \u0026#34;eventID\u0026#34;: \u0026#34;3d4906c8-52ce-456f-bc0a-a89f07b364a0\u0026#34;, \u0026#34;readOnly\u0026#34;: true, \u0026#34;resources\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;AWS::S3::Object\u0026#34;, \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:s3:::aws-cloudtrail-logs-workshop/AWSLogs/*****/CloudTrail/ap-southeast-1/2024/03/03/*****_CloudTrail_ap-southeast-1_20240303T1355Z_FXZWnsQMI7Esmlr6.json.gz\u0026#34; }, { \u0026#34;accountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;AWS::S3::Bucket\u0026#34;, \u0026#34;ARN\u0026#34;: \u0026#34;arn:aws:s3:::aws-cloudtrail-logs-workshop\u0026#34; } ], \u0026#34;eventType\u0026#34;: \u0026#34;AwsApiCall\u0026#34;, \u0026#34;managementEvent\u0026#34;: false, \u0026#34;recipientAccountId\u0026#34;: \u0026#34;*****\u0026#34;, \u0026#34;eventCategory\u0026#34;: \u0026#34;Data\u0026#34;, \u0026#34;tlsDetails\u0026#34;: { \u0026#34;tlsVersion\u0026#34;: \u0026#34;TLSv1.2\u0026#34;, \u0026#34;cipherSuite\u0026#34;: \u0026#34;ECDHE-RSA-AES128-GCM-SHA256\u0026#34;, \u0026#34;clientProvidedHostHeader\u0026#34;: \u0026#34;aws-cloudtrail-logs-workshop.s3.ap-southeast-1.amazonaws.com\u0026#34; } } ] } "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.5-file/",
	"title": "Access the file ",
	"tags": [],
	"description": "",
	"content": "Access the file In bucket console, select file S3_logging_workshop.txt. Copy Object URL. Access the file in browser. "
},
{
	"uri": "//localhost:1313/5-s3athena/",
	"title": "Query logs with Athena",
	"tags": [],
	"description": "",
	"content": "Using Athena with CloudTrail logs is even easier than server access logs. With server access logs, you had to go to the Athena console to create a database and table, but with CloudTrail logging, Athena will automatically create a table for you.\nTo use Athena with CloudTrail logs, simply go to the CloudTrail event history and select Run advanced queries in Amazon Athena.\nGo to CloudTrail console. On left panel, select Event history, select Create Athena table. for Storage location, select bucket aws-cloud-trail-logs-workshop which we are using to store logs then select Create table. Confirm Athena table cloudtrail_logs_aws_cloudtrail_logs_workshop created. Find select service Athena, then select Launch query editor. If this is the first time you use Athena, select Edit settings, if not, skip to step 10. Click Browse S3. Select 1 bucket to store query\u0026rsquo;s result, here we choose bucket logging-workshop-destination. Check and click Save. Check and click Editor to return. Copy the query into the editor, make sure you are using the right table.This query will filter operation GetObject whihc have eventsource is s3.amazonaws.com. select Run. SELECT * FROM cloudtrail_logs_aws_cloudtrail_logs_workshop WHERE eventsource = \u0026#39;s3.amazonaws.com\u0026#39; AND eventname in (\u0026#39;GetObject\u0026#39;) Check the result below. Finally, run this query to drop the table. DROP TABLE `cloudtrail_logs_aws_cloudtrail_logs_workshop` "
},
{
	"uri": "//localhost:1313/6-cleanup/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "We will take the following steps to delete the resources we created in this exercise.\nXóa Athena query Find and select service Athena, then select Launch query editor, select tab Settings, click Manage. Click X to delete the connections to bucket, click Save. Xóa CloudTrail Find and select service CloudTrail, select Trails on left panel. Select trail S3_logging_workshop, then select Delete. Confirm Delete. Xóa S3 buckets Find and select service S3, select bucket logging_workshop. We have to empty the bucket before delete it. Select all files then click Delete. Confirmto delete. click Delete objects. Return to buckets list, then select bucket logging_workshop, select Delete. Confirm bucket\u0026rsquo;s name and click Delete bucket. Repeat delete step from step 5 to delete 2 remainings buckets, logging-workshop-destinations và aws-cloudtrail-log-workshop. "
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]